\documentclass[a0paper,portrait]{baposter}

% Packages

\usepackage[utf8]{inputenc}
\usepackage[american]{babel}

\usepackage{url}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{relsize}

\usepackage{enumitem}
\setlist{leftmargin=5mm}

\usepackage{tikz}
\usetikzlibrary{shapes}
\usepgflibrary{fpu}

% Graphics

\graphicspath{{../figures/}}
\definecolor{TUMBlue}{RGB}{0, 94, 184}

% Custom Commands

\newcommand{\aff}{\textsuperscript{$\star$}}
\newcommand{\compresslist}{
\setlength{\itemsep}{1pt}
\setlength{\parskip}{2pt}
\setlength{\parsep}{2pt}
\vspace{-0.75em}
}

% Bibliography

\usepackage[
  backend=biber,
  sorting=nty,
  style=ieee,
  minbibnames=1,
  maxbibnames=1,
  maxcitenames=1,
  mincitenames=1,
  defernumbers=true,
  natbib=true]{biblatex}
\addbibresource{../lit.bib}

\AtEveryBibitem{%
  \clearfield{url}%
  \clearfield{doi}%
  \clearfield{issn}
  \clearfield{volume}
  \clearfield{number}
  \clearfield{pages}
  \clearfield{isbn}
  \clearfield{eprint}
}

\DefineBibliographyStrings{english}{%
  references = {},
}

\renewcommand\refname{}

% Document

\begin{document}

% Background is white.
% \background

\background{
  \begin{tikzpicture}[remember picture,overlay]%
    % \draw (12.75, 7.5) node {\includegraphics[scale=1]{tiled}};
    % \draw (12.75, 24) node {\includegraphics[scale=1]{tiled}};

    \draw[white, fill=white, rounded corners=1pt]
         (current page.north west)+(1.5, -0.5)
          rectangle ++(20.5, -3.5);

    \draw[white, fill=white, rounded corners=1pt]
         (current page.north east)+(-3.3, -0.5) rectangle ++(-0.4, -3.2);

  \end{tikzpicture}
}


\begin{poster}{
  grid=false,
  eyecatcher=true,
  borderColor=white,
  headerColorOne=TUMBlue,
  headerColorTwo=TUMBlue,
  headerFontColor=white,
  boxColorOne=white,
  headershape=smallrounded,
  background=user,
  headerborder=none,
  textborder=none,
  boxshade=plain,
  headerheight=100pt
}
{
  % Eye Catcher
}
{
  {\bf CytoGAN: Generative Modeling of Cell Images}
  \vspace{3mm}
}
%%% Authors %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
{
  \smaller[0.5]
  \hspace{-3mm}Peter Goldsborough\textsuperscript{$\star$\,\textdagger}, Nick Pawlowski\textsuperscript{$\ddagger$}, Juan C. Caicedo\aff, Shantanu Singh\aff, Anne E. Carpenter\aff

  \vspace{2mm}
  {
    \smaller[1]
    \aff Broad Institute of MIT and Harvard \hspace{3mm}%
    \textdagger\hspace{2pt} Technical University Munich \hspace{3mm}%
    $\ddagger$ Imperial College London
  }
}
% Logos
{
  \begin{tabular}{l}
    \includegraphics[width=0.11\textwidth]{broad-logo}\\
    \vspace{-2mm}\\
    \includegraphics[width=0.11\textwidth]{imperial-logo}
    \vspace{-2mm}\\
    \includegraphics[width=0.11\textwidth]{tum-logo}\\
  \end{tabular}
}

\headerbox{Introduction}{name=intro, column=0, row=0}{

\emph{Morphological profiling} aims to map microscopy images of perturbed cells to salient vector representations that divide the morphological space into clusters of cells with similar properties or function.

\vspace{2mm}

Current approaches are divided between \textbf{a}) classical image processing, requiring manual fine-tuning and expert knowledge, and \textbf{b}) transfer learning with deep CNNs trained on miscellaneous objects, allowing little to no domain-specific adaptation.

\vspace{2mm}

Instead, we model cells with \emph{Generative Adversarial Networks} (GANs) for both representation learning and cell image synthesis. Advantages of our approach include:
\vspace{2mm}
\begin{itemize}
\compresslist
\item \textbf{Adaptability} to training data, allowing identification of the intrinsic semantic relationships between biologically meaningful channels,
\item \textbf{Translation} of learned representations into biological phenotypes.
\end{itemize}
}

\headerbox{Exploring Biological Phenotypes Using Cell Synthesis}{name=synth, span=2, column=1, row=0}{

GANs enable us to synthesize cell images and explore variations in the noise and
learned latent spaces. This allows biologically meaningful experiments and
improves interpretability of our method.

\vspace{-1mm}
\begin{center}
  \begin{tikzpicture}
      \foreach \i/\kind in {0/began, 1/bigan, 2/lsgan, 3/real, 4/wgan} {
        \foreach \j in {0} {
          \draw ({\i * 3}, {\j * 1.5})
          node {\includegraphics[width=2cm, height=2cm]{generated/\kind/\j}};
        }
      }
  \end{tikzpicture}
\end{center}
\vspace{-2mm}

Shown above are cells synthesized with LSGAN, WGAN, BEGAN and BiGAN
architectures alongside a real cell. The synthesized images are not only highly
detailed and realistic, but also consistent with their biological nature. For
example, it is characteristic that $\beta$-Tubulin (green channel) forms a
circular halo cradling the nucleus. This property is maintained clearly in most
generated images. }

\headerbox{Interpolating Cell Images in Noise and Latent Space}{name=interpol, span=2, column=1, row=1, below=synth}{

GANs are known to learn low manifolds of their input priors, such that
interpolation between two points $\mathbf{z}_1, \mathbf{z}_2$ drawn from the noise space $P_{\text{noise}}$ results in visually smooth
transitions in generated images \cite{radford2015unsupervised}. We confirm that this property holds for microscopy cell images.

\vspace{-1mm}
\begin{center}
\begin{tikzpicture}
  \foreach \i in {0, 1} {
    \foreach \j in {0, ..., 9} {
      \draw ({\j * 1.5}, {\i * -1.5}) node
      {\includegraphics[width=1.5cm, height=1.5cm]{noise-interpolation/\i/\j}};
    }

  }
\end{tikzpicture}
\end{center}
\vspace{-2mm}

Bidirectional GANs (BiGANs) \cite{donahue2016adversarial} extend the vanilla DCGAN \cite{radford2015unsupervised} architecture with an
explicit encoder network that enables both synthesis of images from noise
\emph{and} inference of latent representations, in such a way that the noise and
latent space are fused. This means we can encode real cell images, perturb,
transform or in this case interpolate between them and re-synthesize the
resulting images.

\vspace{-2mm}
\begin{center}
\begin{tikzpicture}
    \foreach \i in {0, ..., 9} {
      \draw ({\i * 1.5}, 0) node
      {\includegraphics[width=1.5cm, height=1.5cm]{latent-interpolation/\i}};
    }

    \fill[black] (0.25, -0.75) rectangle ++(12, 2mm);
\end{tikzpicture}
\end{center}
}

\headerbox{Vector Algebra for Biological Interpretability}{name=algebra, span=2, column=1, row=1, below=interpol}{

We find that GANs partition the noise space into regions capturing different semantic properties of cells, allowing biologically meaningful algebra on noise vectors.

\vspace{-3mm}
\begin{center}
\begin{tikzpicture}
    \draw (0, 0) node {\includegraphics[scale=0.4]{algebra/figure-chan}};
    \draw (-3.7, -1.2) node {\footnotesize Much $\beta$-Tubulin}
        ++(2.5, 0) node {\footnotesize Little $\beta$-Tubulin}
        ++(2.5, 0) node {\footnotesize Any Cell}
        ++(2.5, 0) node {\footnotesize More $\beta$-Tubulin}
        ;

    % \draw (0, -2.5) node {\includegraphics[scale=0.4]{algebra/figure-nucl}};
    % \draw (-3.7, -3.7) node {\footnotesize Large Nucleus}
    %     ++(2.5, 0) node {\footnotesize Small Nucleus}
    %     ++(2.5, 0) node {\footnotesize Any Cell}
    %     ++(2.5, 0) node {\footnotesize Larger Nucleus}
        ;
\end{tikzpicture}
\end{center}
\vspace{-3mm}

When the noise and learned latent space are fused (BiGAN), algebra on real cell
images becomes possible. This opens the door to discovery of a whole new class
of highly interpretable and biologically valuable relationships, such as:

\vspace{1mm}
\begin{tikzpicture}
  \draw (-8, 0);
  \draw (0, 0) node [text width=10cm] {
  \begin{itemize}
    \compresslist
    \item $\text{emetine}_{1.0} - \text{emetine}_{0.3} + \text{taxol}_{0.3} \stackrel{?}{=} \text{taxol}_{1.0}$
    \item $\text{Protein Synthesis} - \text{Protein Degradation} \stackrel{?}{=} \text{DMSO}$
    \item $\text{Kinase Inhibitor} - \text{DMSO} + \text{DMSO}' \stackrel{?}{=} \text{Kinase Inhibitor}'$
  \end{itemize}
  };
\end{tikzpicture}
\vspace{-2mm}
}
\headerbox{Representation Learning for Morphological Profiling}{name=rep, span=2, column=1, row=1, below=algebra}{

% We investigate the ability of GANs to learn high quality vector representations
% of cell images and evaluate them quantitatively at the task of
% mechanism-of-action (MOA) prediction. We train a variety of GAN models on 1.3
% million microscopy images of cells perturbed with particular drug compounds,
% average signatures across treatments and predict the MOA via nearest-neighbor
% classification.

We investigate the ability of GANs to learn high quality vector representations
of cells perturbed with particular drug compounds. We want chemicals with
similar effects on cells to have short distances in feature space. We train a variety of
GAN models on 1.3 million cell images, average signatures across treatments, and
predict the effect of unseen chemicals via nearest-neighbor classification.

\vspace{-2mm}
\begin{tikzpicture}
  \draw (-2, 0);
  \draw (0, 0.6) node {\includegraphics[scale=0.22, trim={4cm 3.5cm 8cm 3cm}, clip]{latent-space}};

  \draw (7.75, -0.5) node {\scalebox{0.8}{
    \begin{tikzpicture}[thick]
      \tikzset{box/.style={
        draw, rectangle, rounded corners=0.8pt,
        text width=2.2cm, text height=0.75cm}}
      \tikzset{node/.style={draw, circle, inner sep=0.35cm}}

      % Spacer
      \draw (10.5, 0);

      % Model
      \path (0, 0) coordinate [draw, circle, inner sep=5pt]
            (z) node {$\mathbf{z}$};

      \path (2, 0) coordinate [box] (G) node {Generator};

      \path (4.3, -0.8) coordinate [node] (f) node {$G(\mathbf{z})$};
      \path (4.3, +0.8) coordinate [node] (r) node {$\mathbf{x}$};

      \path (9.5, 0) coordinate [draw, circle, inner sep=7pt]
            (D) node {$\hspace{1pt}\mathbf{D}$};

      % Anchor for real and fake arrows.
      \path (5, 0) coordinate (_);

      \foreach \x/\l in {0/Convolution,%
                         1/Convolution,%
                         2/Convolution,%
                         3/{\hspace{1mm}Dense$(\ell)$\textsuperscript{$\star$}},%
                         4/{Dense$(1)$}%
                         } {
        \path ({5.8 + \x * 0.65}, 0)
              coordinate [box, text width=0.5cm, text height=2cm] (l\x)
              node [rotate=90] {\l};
      }

      % Footnote
      \draw (1.9, -1)
            node {\small{\textsuperscript{$\star$}}\hspace{-1pt} Representations};

      % Edges
      \draw (f) -- (_);
      \draw (r) -- (_);
      \draw [->] (_) -- (l0);
      \draw [->] (l4) -- (D);
      \draw [->] (z) -- (G);
      \draw [->] (G) edge[out=0] (f);
    \end{tikzpicture}
  }};

  \draw (8, 2) node [text width=10.5cm] {
    \begin{center}\textbf{Prediction Accuracy}\end{center}
      \vspace{-1mm}
    \begin{tabular}{ccccc}
      \toprule
      LSGAN & BiGAN & VAE \cite{pawlowski2016msc} & CP \cite{Singh2014} & Transfer Learning \cite{ando2017improving} \\
      \midrule
      68\%/76\%\textsuperscript{\textdagger} & 70\%/72\%\textsuperscript{\textdagger} & 49\% & 90\% & 91\%/96\%\textsuperscript{\textdagger} \\
      \bottomrule \\
    \end{tabular}
  };

  \draw (4.4, 0.7) node {\footnotesize\textdagger\hspace{0.5pt} Whitening Transform};
\end{tikzpicture}
\vspace{-6mm}
}

\headerbox{Code \& Data}{name=code, column=0, row=1, below=intro}{
Code and experiments are available at \url{github.com/goldsborough/cytogan}. Our data is the BBBC021 dataset from the Broad BioImage Benchmark Collection (\url{data.broadinstitute.org/bbbc/BBBC021}).

% REPLACE WITH PAPER!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
% \vspace{-3mm}
% \begin{center}
%   \includegraphics[scale=0.08]{qr-code}\hspace{1cm}\includegraphics[scale=0.08]{qr-code}
%
%   \vspace{-3mm}
%   \hspace{0.1cm}\texttt{Code}\hspace{2.6cm}\texttt{Paper}
% \end{center}
}

\headerbox{Acknowledgements}{name=ack, column=0, row=2, below=code}{
We thank Mike Ando and Google, Inc. for providing computational resources to accelerate our research. We also thank all members of the Broad Imaging Platform for fruitful discussion and their continuous guidance and support.

\vspace{2mm}

This work was supported in part by a grant from the US National Science Foundation (CAREER DBI 1148823 to AEC).

\vspace{1mm}

Nick Pawlowski is supported by Microsoft Research through its PhD Scholarship Program and the EPSRC Centre for Doctoral Training in High Performance Embedded and Distributed Systems (HiPEDS, Grant Reference EP/L016796/1).
}

\headerbox{References}{name=ref, column=0, row=3, below=ack}{
\vspace{-5mm}
\printbibliography
}

\end{poster}
\end{document}
